{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710701891957,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"WNuEkOTbpIv7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mayank_khulbe_farmart_co/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","from torch import nn\n","from torchvision import datasets, transforms\n","import math\n","import time\n","import logging\n","import matplotlib.pyplot as plt\n","import itertools\n","import numpy as np\n","from tqdm import tqdm\n","import torchvision.utils as vutils\n","import os\n","import textwrap\n","import torch.optim as optim\n","\n","#optuna\n","import optuna\n","from optuna.trial import TrialState\n","from optuna.artifacts import FileSystemArtifactStore\n","from optuna.artifacts import upload_artifact\n","\n","#optuna dashboard packages\n","from optuna_dashboard import save_note, register_objective_form_widgets, ChoiceWidget\n","from optuna_dashboard.artifact import get_artifact_path\n","\n","torch.manual_seed(111)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710700004649,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"OxTT99CAqWo2"},"outputs":[],"source":["def get_mnist_loaders(train_batch_size, test_batch_size):\n","    \"\"\"Get MNIST data loaders\"\"\"\n","    train_loader = torch.utils.data.DataLoader(\n","        datasets.MNIST('../data', train=True, download=True,\n","                       transform=transforms.Compose([\n","                           transforms.ToTensor(),\n","                           transforms.Normalize((0.5,), (0.5,))\n","                       ])),\n","        batch_size=train_batch_size, shuffle=True)\n","\n","    test_loader = torch.utils.data.DataLoader(\n","        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                           transforms.ToTensor(),\n","                           transforms.Normalize((0.5,), (0.5,))\n","                       ])),\n","        batch_size=test_batch_size, shuffle=True)\n","\n","    return train_loader, test_loader"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710700011201,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"HXhGsI5oqjZn"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(784, 1024),\n","            nn.LeakyReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(1024, 512),\n","            nn.LeakyReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), 784)\n","        output = self.model(x)\n","        return output"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710700017246,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"UBjrZAGKqpj1"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(128, 256),\n","            nn.LeakyReLU(),\n","            nn.Linear(256, 512),\n","            nn.LeakyReLU(),\n","            nn.Linear(512, 1024),\n","            nn.LeakyReLU(),\n","            nn.Linear(1024, 784),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        output = output.view(x.size(0), 1, 28, 28)\n","        return output"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710700078420,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"ed9kFcYYqrBq"},"outputs":[],"source":["def train_discriminator(discriminator, images, real_labels, fake_images, fake_labels, criterion, d_optimizer):\n","    discriminator.zero_grad()\n","    outputs = discriminator(images)\n","    real_loss = criterion(outputs, real_labels.unsqueeze(1))\n","    real_score = outputs\n","\n","    outputs = discriminator(fake_images)\n","    fake_loss = criterion(outputs, fake_labels.unsqueeze(1))\n","    fake_score = outputs\n","\n","    d_loss = real_loss + fake_loss\n","    d_loss.backward()\n","\n","    d_optimizer.step()\n","    return d_loss, real_score, fake_score"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710700080026,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"q2ARWDyUqs1w"},"outputs":[],"source":["def train_generator(generator, discriminator_outputs, real_labels, criterion, g_optimizer):\n","    generator.zero_grad()\n","    g_loss = criterion(discriminator_outputs, real_labels.unsqueeze(1))\n","    g_loss.backward()\n","\n","    g_optimizer.step()\n","    return g_loss"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710701327946,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"yHfHu8bWsbzA"},"outputs":[],"source":["# Plot grid of 9 images from generator after each epoch\n","def generate_new_images(generator, sample_images, latent_dim, img_dir):\n","    fixed_noise = torch.randn(sample_images, latent_dim).to(device)  # Sample 15 images\n","    fake_images = generator(fixed_noise).to(device)\n","\n","    plt.figure(figsize=(5, 5))\n","    plt.axis(\"off\")\n","    plt.title(\"Generated Images\")\n","    plt.imshow(\n","        np.transpose(\n","            vutils.make_grid(fake_images, nrow=5, padding=1, normalize=True).cpu().numpy(),\n","            (1, 2, 0)\n","        )\n","    )\n","    plt.savefig(img_dir)\n","    plt.show()\n","    plt.close()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":603,"status":"ok","timestamp":1710701850966,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"I25rgt_pquL1"},"outputs":[],"source":["def train_GANs(study: optuna.Study,\n","               artifact_store: FileSystemArtifactStore):\n","\n","    trial = study.ask() #start a trial\n","\n","    print(f\"running trial number: {trial.number}\")\n","\n","    latent_dim = 128\n","\n","    #define the generator and the discriminator\n","    discriminator = Discriminator().to(device=device)\n","    generator = Generator().to(device=device)\n","\n","    cfg = {\n","        \"train_batch_size\": trial.suggest_categorical(\"train_batch_size\", [64, 128]),\n","        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","        \"num_epochs\": 100,\n","        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n","        \"optimizer\": trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n","    }\n","\n","    #define the loader\n","    batch_size = cfg[\"train_batch_size\"]\n","    train_loader, _ = get_mnist_loaders(batch_size, batch_size)\n","\n","\n","    #define the optimizers\n","    lr = cfg['lr']\n","    optimizer_name = cfg['optimizer']\n","    d_optimizer = getattr(optim, optimizer_name)(discriminator.parameters(), lr=lr)  # Instantiate optimizer from name\n","    g_optimizer = getattr(optim, optimizer_name)(generator.parameters(), lr=lr)  # Instantiate optimizer from name\n","\n","    #define the criterion\n","    criterion = nn.BCELoss()\n","\n","    print(f\"Batch Size: {batch_size}\\nLearning Rate: {lr}\\nOptimizer: {optimizer_name}\")\n","\n","    for epoch in range(cfg['num_epochs']):\n","\n","        print(f\"running epoch number: {epoch}\")\n","\n","        for n, (images, _) in tqdm(enumerate(train_loader)):\n","            images = images.to(device)\n","            real_labels = torch.ones(images.size(0)).to(device)\n","\n","            noise = torch.randn(images.size(0), latent_dim).to(device)\n","            fake_images = generator(noise)\n","            fake_labels = torch.zeros(images.size(0)).to(device)\n","\n","            # Train the discriminator\n","            d_loss, real_score, fake_score = train_discriminator(discriminator, images,\n","                                                                 real_labels, fake_images, fake_labels,\n","                                                                  criterion, d_optimizer)\n","\n","            noise = torch.randn(images.size(0), latent_dim).to(device)\n","            fake_images = generator(noise)\n","            outputs = discriminator(fake_images)\n","\n","            # Train the generator\n","            g_loss = train_generator(generator, outputs, real_labels, criterion, g_optimizer)\n","\n","            if (n+1) % len(train_loader) == 0:\n","\n","                print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, '\n","                    'D(x): %.2f, D(G(z)): %.2f'\n","                    % (epoch + 1, cfg['num_epochs'], n + 1, len(train_loader), d_loss.item(), g_loss.item(),\n","                        real_score.mean().item(), fake_score.mean().item()))\n","\n","    img_path = f\"tmp/generated_image-{trial.number}.png\"\n","    generate_new_images(generator, 30, latent_dim, img_path)\n","\n","    artifacts_id = upload_artifact(trial, img_path, artifact_store)\n","    artifact_path = get_artifact_path(trial, artifacts_id)\n","\n","    # 4. Save Note\n","    note = textwrap.dedent(\n","        f\"\"\"\\\n","    ## Trial {trial.number}\n","\n","    Grid of GAN generated images!!\n","    ![generated-images]({artifact_path})\n","\n","    d_loss: {d_loss.item():.2f}\\n g_loss: {g_loss.item():.2f}\n","    \"\"\"\n","    )\n","    save_note(trial, note)\n","\n","    return g_loss.item(), d_loss.item()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":635,"status":"ok","timestamp":1710701904370,"user":{"displayName":"mayank khulbe","userId":"08775446541722101300"},"user_tz":-330},"id":"nqi0naIIxA5p"},"outputs":[],"source":["def start_optimization(artifact_store: FileSystemArtifactStore):\n","    # 1. Create Study\n","    storage = \"sqlite:///db.sqlite3\"\n","    study = optuna.create_study(study_name=\"HITL_with_optuna_for_digit_generation\",\n","                                directions=['minimize', 'maximize'],\n","                                storage=storage,\n","                                load_if_exists=True)\n","\n","    # 2. Set an objective name\n","    study.set_metric_names([\"Are you satisfied with the model's generated images?\", \"Are you satisfied with the model performance?\"])\n","\n","    # 3. Register ChoiceWidget\n","    register_objective_form_widgets(\n","    study,\n","    widgets=[\n","        ChoiceWidget(\n","            choices=[\"Yes ðŸ‘\", \"Somewhat ðŸ‘Œ\", \"No ðŸ‘Ž\"],\n","            values=[-1, 0, 1],\n","            description=\"Please input your score for generated images!\",\n","        ),\n","        ChoiceWidget(\n","            choices=[\"Yes ðŸ‘\", \"Somewhat ðŸ‘Œ\", \"No ðŸ‘Ž\"],\n","            values=[-1, 0, 1],\n","            description=\"Please input your score for model performance!\",\n","        ),\n","    ],\n",")\n","\n","    # 4. Start Human-in-the-loop Optimization\n","    n_batch = 2\n","    while True:\n","        running_trials = study.get_trials(deepcopy=False, states=(TrialState.RUNNING,))\n","        if len(running_trials) >= n_batch:\n","            time.sleep(1)  # Avoid busy-loop\n","            continue\n","        train_GANs(study, artifact_store)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"hfgHFBIHx-tI"},"outputs":[],"source":["def main():\n","    # tmp_path = os.path.join(os.path.dirname(__file__), \"tmp\")\n","    # Get the absolute path to the current notebook file\n","    notebook_dir = os.getcwd()\n","\n","    # Create the absolute path to the \"tmp\" folder\n","    tmp_path = os.path.join(notebook_dir, \"tmp\")\n","\n","    # 1. Create Artifact Store\n","    # artifact_path = os.path.join(os.path.dirname(__file__), \"artifact\")\n","    artifact_path = os.path.join(notebook_dir, \"artifact\")\n","    artifact_store = FileSystemArtifactStore(artifact_path)\n","\n","    print(f\"paths : {tmp_path}, {artifact_path}\")\n","\n","    if not os.path.exists(artifact_path):\n","        os.mkdir(artifact_path)\n","\n","    if not os.path.exists(tmp_path):\n","        os.mkdir(tmp_path)\n","\n","    # 2. Run optimize loop\n","    start_optimization(artifact_store)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/tmp/ipykernel_123637/3673421781.py:12: ExperimentalWarning: FileSystemArtifactStore is experimental (supported from v3.3.0). The interface can change in the future.\n","  artifact_store = FileSystemArtifactStore(artifact_path)\n","[I 2024-03-23 18:27:58,540] Using an existing study with name 'HITL_with_optuna_for_digit_generation' instead of creating a new one.\n","/var/tmp/ipykernel_123637/795455652.py:10: ExperimentalWarning: set_metric_names is experimental (supported from v3.2.0). The interface can change in the future.\n","  study.set_metric_names([\"Are you satisfied with the model's generated images?\", \"Are you satisfied with the model performance?\"])\n"]},{"name":"stdout","output_type":"stream","text":["paths : /home/mayank_khulbe_farmart_co/fmt/Optuna/experiments/tmp, /home/mayank_khulbe_farmart_co/fmt/Optuna/experiments/artifact\n","running trial number: 1\n"]},{"name":"stderr","output_type":"stream","text":["/var/tmp/ipykernel_123637/1745323387.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-3),\n"]},{"name":"stdout","output_type":"stream","text":["Batch Size: 64\n","Learning Rate: 0.0001246434430052504\n","running epoch number: 0\n"]},{"name":"stderr","output_type":"stream","text":["938it [00:17, 53.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Step[938/938], d_loss: 0.1662, g_loss: 3.3386, D(x): 0.96, D(G(z)): 0.06\n","running epoch number: 1\n"]},{"name":"stderr","output_type":"stream","text":["938it [00:16, 55.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/100], Step[938/938], d_loss: 0.1160, g_loss: 3.4485, D(x): 0.99, D(G(z)): 0.10\n","running epoch number: 2\n"]},{"name":"stderr","output_type":"stream","text":["938it [00:16, 56.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/100], Step[938/938], d_loss: 0.0396, g_loss: 5.1803, D(x): 0.99, D(G(z)): 0.03\n","running epoch number: 3\n"]},{"name":"stderr","output_type":"stream","text":["938it [00:17, 55.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/100], Step[938/938], d_loss: 0.0987, g_loss: 5.7693, D(x): 1.00, D(G(z)): 0.07\n","running epoch number: 4\n"]},{"name":"stderr","output_type":"stream","text":["526it [00:09, 56.03it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     main()\n","Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     os\u001b[39m.\u001b[39mmkdir(tmp_path)\n\u001b[1;32m     22\u001b[0m \u001b[39m# 2. Run optimize loop\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m start_optimization(artifact_store)\n","Cell \u001b[0;32mIn[9], line 36\u001b[0m, in \u001b[0;36mstart_optimization\u001b[0;34m(artifact_store)\u001b[0m\n\u001b[1;32m     34\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# Avoid busy-loop\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m train_GANs(study, artifact_store)\n","Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mtrain_GANs\u001b[0;34m(study, artifact_store)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cfg[\u001b[39m'\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     40\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrunning epoch number: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mfor\u001b[39;00m n, (images, _) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_loader)):\n\u001b[1;32m     43\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m         real_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mto(device)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img\u001b[39m.\u001b[39;49mnumpy(), mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/PIL/Image.py:3103\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[0;32m-> 3103\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/PIL/Image.py:3018\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     args \u001b[39m=\u001b[39m mode, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[1;32m   3017\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m _MAPMODES:\n\u001b[0;32m-> 3018\u001b[0m     im \u001b[39m=\u001b[39m new(mode, (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m   3019\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39m_new(core\u001b[39m.\u001b[39mmap_buffer(data, size, decoder_name, \u001b[39m0\u001b[39m, args))\n\u001b[1;32m   3020\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/PIL/Image.py:2925\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageColor\n\u001b[1;32m   2923\u001b[0m     color \u001b[39m=\u001b[39m ImageColor\u001b[39m.\u001b[39mgetcolor(color, mode)\n\u001b[0;32m-> 2925\u001b[0m im \u001b[39m=\u001b[39m Image()\n\u001b[1;32m   2926\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(color, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(color) \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n\u001b[1;32m   2927\u001b[0m     \u001b[39m# RGB or RGBA value for a P image\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImagePalette\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/PIL/Image.py:512\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    509\u001b[0m format_description \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    510\u001b[0m _close_exclusive_fp_after_loading \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39m# FIXME: take \"new\" parameters / other image?\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     \u001b[39m# FIXME: turn mode and size into delegating properties?\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOFaTqsdQJ8mx9RPBdK0fmu","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"optuna","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"vscode":{"interpreter":{"hash":"11ac6faa9248008d391a7540e44edcb95f152bb1f0fd3624523abee6a1a360c7"}}},"nbformat":4,"nbformat_minor":0}
